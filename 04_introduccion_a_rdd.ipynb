{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![img/pythonista.png](img/pythonista.png)](https://www.pythonista.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a *Resilient Distributed Datasets (RDD)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder procesar de forma distribuida grandes volúmenes de datos, *Apache Spark* utiliza los *Resilient Distributed Datasets (RDD)*, los cuales son abstracciones de datos que pueden ser particionadas y ditribuidas de forma consistente dentro del cluster por medio del *SparkContext* y también pueden ser operados de forma paralela.\n",
    "\n",
    "Un *RDD* es una colección de datos que no necesariamente debe de tener una estructura o esquema.\n",
    "\n",
    "El objetivo principal de los *RDD* es el de garantizar.\n",
    "\n",
    "* La adecuada ejecución de cargas de cómputo en memoria.\n",
    "* Realización de operaciones de evaluación \"perezosa\" (*lazy evaluation*).\n",
    "* Garantizar la tolerancia a fallos.\n",
    "* Garantizar la inmutabilidad de los datos.\n",
    "* Contar con la capacidad de particionamiento de los datos en un clúster.\n",
    "* Garantizar la persistencia de los datos.\n",
    "* Permitir la realización de operaciones granulares.\n",
    "\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un *RDD*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen dos formas de crear un *RDD*.\n",
    "\n",
    "* Utilizando el método [```pyspark.SparkContext.parallelize()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.parallelize.html) sobre una colección de *Python*.\n",
    "* Referenciando un [*dataset* externo](https://spark.apache.org/docs/latest/rdd-programming-guide.html#external-datasets) en un sistema de almacenamiento externo.\n",
    "    * [```SparkContext.textFile()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.textFile.html)\n",
    "    * [```SparkContext.wholeTextFiles()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.wholeTextFiles.html)\n",
    "    * [```SparkContext.pickleFile()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.pickleFile.html)\n",
    "    * [```SparkContext.sequenceFile()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.sequenceFile.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La siguiente celda creará una aplicación de *Spark*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://f04046222538:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Introduccion a RDD</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc6d59052d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Introduccion a RDD\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La siguiente celda creará un *RDD* llamado ```rdd_lista``` a partir de un objeto de tipo ```list``` de *Python*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_lista = spark.sparkContext.parallelize([1, 2, 3, [4, 5], 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd_lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La siguiente celda leerá el archivo de texto [```data/quijote.txt```](data/quijote.txt), el cual contiene el texto completo del libro \"El ingenioso hidalgo don Quijote de la Mancha\" de Miguel de Cervantes Saavedra el cual fue publicado por el [proyecto Gutenberg](https://www.gutenberg.org/files/2000/2000-0.txt) y creará el *RDD* con nombre ```rdd_texto```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto = spark.sparkContext.textFile('data/quijote.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones de *RDDs*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones son acciones que pueden ser asignadas como tareas de procesamiento de un clúster. Los *RRD* pueden realizar operaciones de dos tipos:\n",
    "\n",
    "* [**Transformaciones**](https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations). Son operaciones perezosas, que dan por resultado un nuevo *RDD*. Una operación perezosa no se realiza hasta que el objeto resultante de dicha operación se utilizado. Algunas transformaciones son [```flatMap()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.flatMap.html), [```map()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.map.html), [```reduceByKey()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.reduceByKey.html), [```filter()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.filter.html), [```sortByKey()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.sortByKey.html).\n",
    "* [**Acciones**](https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions). Son operaciones que realizan cómputos a partir del *RDD* y regresan algún valor. Algunas acciones son [```count()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.count.html), [```collect()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.collect.html), [```first()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.first.html), [```max()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.max.html), [```reduce()```](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.reduce.html).\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-operations\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-pyspark-rdd-operations/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_lista.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.lista.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas_quijote = rdd_texto.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lineas_quijote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas_quijote[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto.flatMap(lambda x: x.split(\" \")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_quijote = rdd_texto.flatMap(lambda x: x.split(\" \"))\\\n",
    "    .filter(lambda x: x != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_quijote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_quijote.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de conteo de palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_palabras = palabras_quijote.map(lambda palabra: (palabra, 1))\\\n",
    "    .reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conteo_palabras.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_ord = conteo_palabras.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_ord.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_50 = conteo_ord.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_texto.flatMap(lambda x: x.split(\" \"))\\\n",
    "    .filter(lambda x: x != None)\\\n",
    "    .map(lambda palabra: (palabra, 1))\\\n",
    "    .reduceByKey(lambda a, b: a + b)\\\n",
    "    .sortBy(lambda x: x[1], ascending=False)\\\n",
    "    .take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones de escritura de un *RDD*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.saveAsTextFile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
